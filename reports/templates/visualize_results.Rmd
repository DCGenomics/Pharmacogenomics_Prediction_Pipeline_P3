---
title: "P3: Visualization of Results"
date: "`r format(Sys.time(), '%d %B, %Y')`"
params:
    results_glob_str: ""
    output_dir: ""
output:
  html_document:
    theme: cosmo
    toc: true
    toc_float: true
    number_sections: true
  pdf_document:
    dev: png
    toc: true
    latex_engine: xelatex
---

```{r load_libs, message=FALSE, warning=FALSE, include=FALSE}
library('DT')
library('dplyr')
library('knitr')
library('ggplot2')
library('gplots')
library('reshape2')
library('stringr')
library('SuperLearner')
library('RColorBrewer')
library('org.Hs.eg.db')
library('GO.db')
source('R/results_helper_functions.R')

options(stringsAsFactors=FALSE,
        knitr.duplicate.label='allow',
        digits=4)

# If rmarkdown.pandoc.to not specified (for example, when kniting
# piece-by-piece in Vim-R), have it default to 'latex' output.
if (is.null(opts_knit$get("rmarkdown.pandoc.to"))) {
    opts_knit$set(rmarkdown.pandoc.to='latex')
}

# For images containing unicode text, we will use cairo for PDF output
if (opts_knit$get("rmarkdown.pandoc.to") == 'latex') {
    opts_chunk$set(dev='cairo_pdf', 
  				   dev.args=list(cairo_pdf=list(family="DejaVu Sans")),
                   fig.width=1920/192,
                   fig.height=1920/192,
                   dpi=192)
} else {
    # HTML output
    opts_chunk$set(dev='png',
                   fig.width=1080/192,
                   fig.height=1080/192,
                   dpi=192, fig.retina=2)
}
```

Results
=======

### Load SuperLearner results

```{r run1, message=FALSE}
# results_glob_str should look like '~/P3/renamed/runs/run_1/output/*.RData'
run            <- parse_p3_results(Sys.glob(results_glob_str))
coefs          <- run$coefs
cv_risks       <- run$cv_risks
var_importance <- run$var_importance
```

### Summary of SuperLearner predictor performance

#### Absolute CV risk

```{r predictor_performance, results='asis'}
# CV risk averages across all drugs
cv_risks_long <- melt(cv_risks)
colnames(cv_risks_long) <- c('drug', 'learner', 'value')
cv_risks_long$learner <- as.character(cv_risks_long$learner)

cvrisk_averages <- cv_risks_long %>% 
    group_by(learner) %>% 
    summarise(average_risk=mean(value, na.rm=TRUE))

# Coefficient averages across all drugs
coefs_long <- melt(coefs)
colnames(coefs_long) <- c('drug', 'learner', 'value')
coefs_long$learner <- as.character(coefs_long$learner)

coef_averages <- coefs_long %>% 
    group_by(learner) %>% 
    summarise(average_coef=mean(value, na.rm=TRUE)) %>%
    arrange(desc(average_coef))

combined <- merge(cvrisk_averages, coef_averages, by='learner') %>%
    arrange(desc(average_coef))
xkable(combined)
```

#### Relative CV risk

##### Relative CV risk for each Learner

```{r, results='asis', fig.cap='Distribution of relative CV risks'}
rel_risks <- 1 - (cv_risks/cv_risks[,'mean']) 
rel_risks <- rel_risks[,colnames(rel_risks) != 'mean']

summary_df <- as.data.frame(cbind(min=apply(rel_risks, 2, min), 
                                  median=apply(rel_risks, 2, median),
                                  max=apply(rel_risks, 2, max))) %>%
                arrange(desc(median))
xkable(summary_df, caption='Relative CV risk by algorithm')

rel_risks_long <- melt(rel_risks)
colnames(rel_risks_long) <- c('drug', 'learner', 'value')

ggplot(rel_risks_long, aes(x=value, fill=learner)) + 
    geom_density(alpha=0.75) +
    geom_vline(xintercept=0, colour="red", linetype = "longdash") +
    xlim(-0.5, 0.5)
```

##### Number of relative risk scores > 0.10 for each learner

```{r, results='asis'}
interesting_hits <- as.data.frame(apply(rel_risks, 2, function (x) { sum(x > 0.10) }))
colnames(interesting_hits) <- 'num'
xkable(interesting_hits)
```

##### Number of NA's in CV risk output

```{r}
has_nas <- apply(cv_risks, 2, function(x) { sum(is.na(x)) })
has_nas[has_nas > 0]
```

#### Absolute vs. Relative risk

```{r}
abs_vs_rel <- cbind(cv_risks_long  %>% filter(learner != 'mean') %>%
                    dplyr::rename(absolute=value),
                    relative=rel_risks_long$value)

# Plot 4 at a time using facet grid
learners <- unique(abs_vs_rel$learner)
learner_groups <- split(learners, ceiling(seq_along(learners) / 4))

for (learners in learner_groups) {
    plt <- ggplot(abs_vs_rel %>% filter(learner %in% learners), 
                  aes(x=relative, y=absolute, color=learner)) + 
            geom_point() +
            geom_vline(xintercept=0, colour="#999999", linetype="longdash", size=0.3) +
            xlim(-0.5, 0.5) + 
            facet_wrap(~learner, ncol=2)
    print(plt)
}
```

### Feature importance

First, let's create a vector of feature types so that we can group our 
plots this way.

```{r feature_types}
# types of predictor features
feature_types <- c('cnv_clusters', 'cnv_longest_gene', 'cnv_max_gene',
                   'cpdb_variants', 'cpdb_zscores', 'exome_variants',
                   'go_variants', 'go_zscores', 'msigdb_variants',
                   'msigdb_zscores', 'normed_counts', 'zscores_zscores')

ftype <- rep(NA, nrow(var_importance)) 
for (cls in feature_types) {
    ftype[grepl(cls, rownames(var_importance))] <- cls
}
```

#### Distribution of feature average variable importance

Median RF variable importance for each feature across all drugs.

```{r variable_importance_dist, results='asis'}
median_var_importance <- apply(var_importance, 1, median)  

# Create a feature/type mapping
median_type_importance <- as.data.frame(
    cbind(median_var_importance=as.vector(median_var_importance), type=ftype)
)

# Density grouped by feature type
ggplot(median_type_importance, aes(x=median_var_importance, 
                                   fill=type, color=type, group=type)) +
    geom_density(alpha=0.15) +
    xlab('Median Random Forest Variable Importance')

df <- median_type_importance %>% 
        group_by(type) %>%
        summarize(avg=mean(as.numeric(median_var_importance))) %>%
        arrange(desc(avg))
xkable(df)
```

#### Distribution of feature maximum variable importance

```{r variable_importance_dist}
max_var_importance <- apply(var_importance, 1, max) 

# Create a feature/type mapping
max_type_importance <- as.data.frame(
    cbind(max_var_importance=as.vector(max_var_importance), type=ftype)
)

# Density grouped by feature type
ggplot(max_type_importance, aes(x=max_var_importance, 
                                 fill=type, color=type, group=type)) +
    geom_density(alpha=0.15) +
    xlab('Maximum Random Forest Variable Importance')

df <- max_type_importance %>% 
        group_by(type) %>%
        summarize(avg=mean(as.numeric(max_var_importance))) %>%
        arrange(desc(avg))
xkable(df)
```

#### Features with highest average variable importance

Features ranked by _median_ random forest variable importance across all drugs.

```{r results='asis', message=FALSE}
highest_median_var_importance <- as.data.frame(sort(median_var_importance, decreasing=TRUE))
colnames(highest_median_var_importance) <- c('Importance')
highest_median_var_importance <- add_rownames(highest_median_var_importance, 'Feature')

# add human-readable annotations
highest_median_var_importance$Description = get_feature_descriptions(highest_median_var_importance$Feature)

xkable(highest_median_var_importance, 15, 
       caption='Features ranked by median variable importance',
       str_max_width=60)

write.table(highest_median_var_importance, sep='\t', quote=FALSE,
            file=file.path(output_dir, 'highest_median_var_importance.tab'))
```

#### Features with highest maximum variable importance

Features ranked by _max_ random forest variable importance across all drugs.

```{r results='asis', message=FALSE}
highest_max_var_importance <- as.data.frame(sort(max_var_importance, decreasing=TRUE))
colnames(highest_max_var_importance) <- c('Importance')
highest_max_var_importance <- add_rownames(highest_max_var_importance, 'Feature')

# add human-readable annotations
highest_max_var_importance$Description = get_feature_descriptions(highest_max_var_importance$Feature)

xkable(highest_max_var_importance, 15, 
       caption='Features ranked by max variable importance',
       str_max_width=60)

write.table(highest_max_var_importance, sep='\t', quote=FALSE,
            file=file.path(output_dir, 'highest_max_var_importance.tab'))
```

#### Features with the highest trimmed mean variable importance

Features ranked by _mean_ of their top N=10 variable importance scores. Since
different features are likely to help predict responses for different drugs,
this helps us to find features which performed well for at least some subset of
the drugs.

```{r results='asis', message=FALSE}
# Number of highest scoring drugs to average across
n <- 10

top_n <- apply(var_importance, 1, function(x) { mean(head(sort(x, decreasing=TRUE), n)) }) 
trimmed_mean_import <- as.data.frame(sort(top_n, decreasing=TRUE))
colnames(trimmed_mean_import) <- c('Importance')
trimmed_mean_import <- add_rownames(trimmed_mean_import, 'Feature')

trimmed_mean_import$Description = get_feature_descriptions(trimmed_mean_import$Feature)

xkable(trimmed_mean_import, 15, 
       caption='Features ranked by trimmed-mean variable importance.',
       str_max_width=60)

write.table(trimmed_mean_import, sep='\t', quote=FALSE,
            file=file.path(output_dir, 'trimmed_mean_importance.tab'))
```

### Drug performance

#### Drugs with shared predictive features

Next, we will see if there are any groups of drugs which are predicted by
similar sets of features. To do this, we will cluster the drugs based on the
their feature importance vectors.

```{r drug_heatmap, fig.width=1080/96, fig.height=1080/96, dpi=96}
heatmap_colors <- colorRampPalette(brewer.pal(9, "YlGnBu"))(100)
dist_matrix <- cor(var_importance, method='spearman')

dendrogram <- ifelse(nrow(dist_matrix) > 100, 'none', 'column')

heatmap.2(dist_matrix, trace="none", labRow=NA, dendrogram=dendrogram,
		  main="Drug prediction similarity", margins=c(12,8),
		  xlab='Drug', ylab='Drug', col=heatmap_colors)
```

